{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Notebook\n",
    "\n",
    "This notebook contains code to clean and consolidate the extremely messy pricing files of US hospitals, which were extracted from hospital websites in a very large scraping exercise. There are many steps required to clean the files, which are each contained in different sections below. The files contained in `checked_files`, which can be dowloaded from [this dropbox link](https://www.dropbox.com/sh/afpoveqn7elmzkn/AACTMyNvGZ3ZtCe08ualKrRba?dl=0), have already been checked to be \"openable\" and to likely be pricing files. There are roughly x separate discrete steps - - each of which are described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Find Unique Files\n",
    "\n",
    "The scraping exercise would often download the same file multiple times because 1) files are often available at multiple addresses and 2) our crawling procedure found the same price file/url for multiple hospitals. The code below attempts to identify the unique files within each hospital folder and returns their paths. Note that, because of 2) above, we'll eventually need to check across hospitals to ensure that the same file isn't being used for multiple hospitals. For memory reasons, this will likely require a comparison based on file object rather than opened dataframe contents. See [this Stack Exchange post](https://stackoverflow.com/questions/748675/finding-duplicate-files-and-removing-them) for ideas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_filecheck(df_list, path_list): \n",
    "    \"\"\"\n",
    "    Returns the unique dataframes and their paths\n",
    "    from an initial list of dataframes and paths\n",
    "    \"\"\"\n",
    "  \n",
    "    unique_df_list, unique_path_list = [], []\n",
    "      \n",
    "    # traverse for all elements \n",
    "    for dataframe, path in zip(df_list, path_list): \n",
    "        \n",
    "        check = [dataframe.equals(x) for x in unique_df_list]\n",
    "        if np.sum(check) == 0:\n",
    "            unique_df_list.append(dataframe)\n",
    "            unique_path_list.append(path)\n",
    "    \n",
    "    return(unique_path_list)\n",
    "\n",
    "def get_unique_paths(home_folder):\n",
    "    \"\"\"\n",
    "    Returns list of paths to unique files within\n",
    "    each hospital sub-folder of the home_folder\n",
    "    \"\"\"\n",
    "    \n",
    "    unique_dfs, unique_paths = [], []\n",
    "    \n",
    "    # Get list of hospitals in folder\n",
    "    folders = os.listdir(home_folder)\n",
    "\n",
    "    # Loop over each hospital checking for its unique files\n",
    "    for folder in folders:\n",
    "    \n",
    "        # First compile all dataframes and their paths into lists\n",
    "        df_list, path_list = [], []\n",
    "        files = os.listdir(home_folder + folder)\n",
    "        for file in files:\n",
    "\n",
    "            fname = home_folder + folder + \"/\" + file\n",
    "\n",
    "            if \".csv\" in file:\n",
    "\n",
    "                # Read file\n",
    "                df = pd.read_csv(fname,index_col=False)\n",
    "\n",
    "                # Add to list\n",
    "                df_list.append(df)\n",
    "                path_list.append(fname)\n",
    "\n",
    "            if \".xls\" in file:\n",
    "\n",
    "                # Read file\n",
    "                df = pd.read_excel(fname,index_col=False)\n",
    "\n",
    "                # Add to list\n",
    "                df_list.append(df)\n",
    "                path_list.append(fname)\n",
    "        \n",
    "        # Second, find the unique dataframes and their lists for that hospital\n",
    "        unique_paths += unique_filecheck(df_list,path_list)\n",
    "        \n",
    "    return(unique_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Open Clean DataFrames\n",
    "\n",
    "The pricing files come in an enormous variety of formats. For example, not all header rows are in the first row of the file, there are often notes or introductory text in the files, there are blank columns, variables names are inconsistent etc. The code below attempts to deal with these various issues. The first function searches for the location of the headers within a file. The second function uses this information to open the file into a clean dataframe format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_header_row(df):\n",
    "    \"\"\"\n",
    "    Returns the row within a file that is likely the header.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create FALSE flag when cell has NAN entry\n",
    "    df_flag = ~df.isnull()\n",
    "    \n",
    "    # Loop over rows to find last row of all NANs. The row below that will be the header row.\n",
    "    # We also make sure that there were just a few NA's above it. This takes care of the files\n",
    "    # with notes at the bottom.\n",
    "    headrow, consecutive_nonNA_rows = 0, 0\n",
    "    for index, row in df_flag.iterrows():\n",
    "        consecutive_nonNA_rows += 1\n",
    "        if (sum(row) == 0) & (consecutive_nonNA_rows < 40):\n",
    "            headrow, consecutive_nonNA_rows = index + 2, 0\n",
    "\n",
    "    return(headrow)\n",
    "\n",
    "def open_file(fname):\n",
    "    \"\"\"\n",
    "    Returns a pandas dataframe from a file name.\n",
    "    Takes care of various formatting issues.\n",
    "    \"\"\"\n",
    "    \n",
    "    if \".csv\" in fname:\n",
    "            \n",
    "        # Read file\n",
    "        df = pd.read_csv(fname,index_col=False)\n",
    "        d = pd.read_csv(fname,index_col=False,skiprows=find_header_row(df))\n",
    "            \n",
    "    if \".xls\" in fname:\n",
    "   \n",
    "        # Read file\n",
    "        df = pd.read_excel(fname,index_col=False)\n",
    "        d = pd.read_excel(fname,index_col=False,skiprows=find_header_row(df))\n",
    "    \n",
    "    # Remove Unnamed columns\n",
    "    droplist = [i for i in d.columns if i.startswith('Unnamed')]\n",
    "    d.drop(droplist,axis=1,inplace=True)\n",
    "    \n",
    "    return(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore Variable/Header Names\n",
    "\n",
    "Pricing files generally assign each price either to a text description of a service/product, or to a code representing that service/product. When merging prices across hospitals, we want be able to distinguish price, description and code columns, so that we can make sure that we are merging dataframes on the right variables. The first function below extracts all unique header labels from all the files specified within a list. The idea is that we can manually inspect this information to come up with good keywords to identify the appropriate columns. The next function then uses these keywords to create two lists - one with all the unique text descriptive labels from the datasets and the other with all the unique codes, which we can use to identify the columns in the section below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_header_labels(unique_paths):\n",
    "    \"\"\"\n",
    "    Returns all unique headersfrom a set of\n",
    "    files defined in `unique_paths`.\n",
    "    \"\"\"\n",
    "    headers = []\n",
    "    for file in unique_paths:\n",
    "        df = open_file(file)\n",
    "        headers += list(df.columns.values)\n",
    "\n",
    "    # Print to manually inspect header values in order to group the below\n",
    "    return(Counter(headers))\n",
    "\n",
    "def get_descriptive_labels(unique_paths,description_kws,code_kws):\n",
    "    \"\"\"\n",
    "    Returns lists of unique code and description labels defined by\n",
    "    `description_kws` and `code_kws` from a set of files defined\n",
    "    in `unique_paths`.\n",
    "    \"\"\"\n",
    "    \n",
    "    descriptions, codes = [], []\n",
    "    for file in unique_paths:\n",
    "\n",
    "        df = open_file(file)\n",
    "\n",
    "        # Get descriptive columns\n",
    "        description_cols = [i for i in df.columns if any(x in i.lower() for x in description_kws)]\n",
    "        if  description_cols:\n",
    "            d = df[description_cols]\n",
    "            descriptions += d.iloc[:,0].tolist()\n",
    "\n",
    "        # Get code columns\n",
    "        code_cols = [i for i in df.columns if any(x in i.lower() for x in code_kws)]\n",
    "        if code_cols:\n",
    "            d = df[code_cols]\n",
    "            codes += d.iloc[:,0].tolist()\n",
    "    \n",
    "    descriptions, codes = list(set(descriptions)), list(set(codes))\n",
    "    \n",
    "    return([x for x in descriptions if str(x) != 'nan'],[x for x in codes if str(x) != 'nan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merge Files Based on Exact Description and/or Code Match\n",
    "\n",
    "As discussed, we need to merge the pricing files based either on their product/service text descriptions and/or their product/service codes. The first function below creates a merged dataframe using all the files in `unique_paths` that have columns identified in the `index_kws` list. The merging is based on exact matches of the contents of the `index_kws` column. Note that we should improve this by using fuzzy matching at some point. The next function attempts to map text descriptions to codes based on files that happen to contain both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(unique_paths,price_kws,index_col,index_kws):\n",
    "    \"\"\"\n",
    "    Returns a merged pricing file of all files in `unique_paths`\n",
    "    that have columns with keywords in `index_kws` and `price_kws`\n",
    "    and merges based on matches in the columns identified using\n",
    "    `index_kws`.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initiate merged dataframe\n",
    "    d_merged = pd.DataFrame({'desc':index_col})\n",
    "    d_merged.set_index('desc',inplace=True)\n",
    "\n",
    "    # Loop over files, extract relevant columns and merge\n",
    "    for file in unique_paths:\n",
    "\n",
    "        # Open file\n",
    "        print(file)\n",
    "        df = open_file(file)\n",
    "\n",
    "        # Get price columns (choose the last column if multiple)\n",
    "        price_cols = [i for i in df.columns if any(x in i.lower() for x in price_kws)]\n",
    "        price_cols = price_cols[-1:]   \n",
    "\n",
    "        # Get descriptive/code columns\n",
    "        desc_cols = [i for i in df.columns if any(x in i.lower() for x in index_kws)]\n",
    "\n",
    "        if (len(price_cols) > 0) & (len(desc_cols) > 0):\n",
    "\n",
    "            # Extract relevant columns from dataframe\n",
    "            d = df.loc[:,[desc_cols[0],price_cols[0]]]\n",
    "\n",
    "            # Remove '$' sign from price column\n",
    "            d.loc[:,price_cols[0]] = d.loc[:,price_cols[0]].replace('[\\$,]', '', regex=True)\n",
    "            d.loc[:,price_cols[0]] = pd.to_numeric(d.loc[:,price_cols[0]],errors='coerce')\n",
    "\n",
    "            # Take average when there are multiple rows with same label\n",
    "            d = d.groupby(desc_cols[0]).mean()\n",
    "\n",
    "            # Merge to dataframe\n",
    "            d_merged = d_merged.merge(d,left_index=True, right_index=True,how='left')\n",
    "\n",
    "            # Rename Price Column to Hospital Name\n",
    "            hospital_name = file.split(\"/\")[2]\n",
    "            d_merged.rename(columns={price_cols[0]:hospital_name},inplace=True)\n",
    "    \n",
    "    return(d_merged)\n",
    "\n",
    "def match_desc_code(unique_paths,desc_col,description_kws,code_kws):\n",
    "    \"\"\"\n",
    "    Returns a dataframe mapping text descriptions to codes.\n",
    "    \"\"\"\n",
    "    # Initiate merged dataframe\n",
    "    d_desc_code = pd.DataFrame({'desc':desc_col})\n",
    "    d_desc_code.set_index('desc',inplace=True)\n",
    "\n",
    "    # Loop over files, extract relevant columns and merge\n",
    "    for file in unique_paths:\n",
    "\n",
    "        # Open file\n",
    "        df = open_file(file)\n",
    "        print(file)\n",
    "\n",
    "        # Get description columns\n",
    "        desc_cols = [i for i in df.columns if any(x in i.lower() for x in description_kws)]\n",
    "\n",
    "        # Get code columns\n",
    "        code_cols = [i for i in df.columns if any(x in i.lower() for x in code_kws)]\n",
    "\n",
    "        if (len(code_cols) > 0) & (len(desc_cols) > 0):\n",
    "\n",
    "            # Extract relevant columns from dataframe\n",
    "            d = df.loc[:,[desc_cols[0],code_cols[0]]]\n",
    "            d.set_index(desc_cols[0],inplace=True)\n",
    "\n",
    "            # Merge to dataframe\n",
    "            d_desc_code = d_desc_code.merge(d,left_index=True, right_index=True,how='left')\n",
    "\n",
    "    # Drop duplicates\n",
    "    d_desc_code.drop_duplicates(keep = 'first', inplace = True) \n",
    "\n",
    "    # Stack the columns and the index\n",
    "    df_idx = pd.DataFrame({'desc':d_desc_code.index})\n",
    "    df_idx = pd.concat([df_idx]*len(d_desc_code.columns),ignore_index=True)\n",
    "    df_idx['code'] = sorted(it.chain(*d_desc_code.values))\n",
    "\n",
    "    # Clean up df\n",
    "    df_idx.dropna(inplace = True)\n",
    "    df_idx = df_idx.drop_duplicates(keep = 'first').reset_index(drop=True)\n",
    "\n",
    "    return(df_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Analyses\n",
    "\n",
    "The code below runs the functions defined above to compile a merged dataframe of hospital prices. We start with just Washington DC hospitals, which are [here](https://www.dropbox.com/sh/32pjpd7ix00wg8m/AABEWzJirpWalstZGHyBaiKHa?dl=0), to make sure it runs properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Hospitals: 7\n",
      "Total Number of Files: 21\n",
      "Counter({'PROCEDURE NAME': 5, 'UNIT CHG AMT.': 5, 'SVC CODE': 4, 'SERVICES DESCRIPTION': 4, 'CHGAMT': 4, 'Price': 4, 'Procedure Description': 2, 'Description': 2, 'FEE SCHED ID': 1, 'FEE SCHEDULE NAME': 1, 'PROC CODE': 1, 'CPT CODE': 1, 'CPT EFF. DATE': 1, 'UB CODE': 1, 'MSDRG': 1, 'DRG Name': 1, 'Avg Charge': 1, 'Charge Description': 1, 'Standard Charge': 1, 'DRG': 1, 'MS-DRG Description': 1, 'Average of Chgs': 1})\n",
      "../DC_hospitals/SIBLEY MEMORIAL HOSPITAL/4.xlsx\n",
      "../DC_hospitals/SIBLEY MEMORIAL HOSPITAL/8.xlsx\n",
      "../DC_hospitals/SIBLEY MEMORIAL HOSPITAL/7.xls\n",
      "../DC_hospitals/SIBLEY MEMORIAL HOSPITAL/6.xls\n",
      "../DC_hospitals/SIBLEY MEMORIAL HOSPITAL/5.xls\n",
      "../DC_hospitals/MEDSTAR GEORGETOWN UNIVERSITY HOSPITAL/1.csv\n",
      "../DC_hospitals/MEDSTAR GEORGETOWN UNIVERSITY HOSPITAL/0.xlsx\n",
      "../DC_hospitals/MEDSTAR WASHINGTON HOSPITAL CENTER/0.xls\n",
      "../DC_hospitals/CHILDREN'S HOSPITAL NMC/0.csv\n",
      "../DC_hospitals/PROVIDENCE HOSPITAL WASHINGTON DC/0.csv\n",
      "../DC_hospitals/PROVIDENCE HOSPITAL WASHINGTON DC/2.xlsx\n",
      "../DC_hospitals/PROVIDENCE HOSPITAL WASHINGTON DC/1.xlsx\n",
      "../DC_hospitals/HOWARD UNIVERSITY HOSPITAL/1.csv\n",
      "../DC_hospitals/HOWARD UNIVERSITY HOSPITAL/0.xlsx\n",
      "../DC_hospitals/UNITED MEDICAL CENTER/StandardCharges12202018.xls\n",
      "../DC_hospitals/UNITED MEDICAL CENTER/DRGFile.xls\n",
      "../DC_hospitals/SIBLEY MEMORIAL HOSPITAL/4.xlsx\n",
      "../DC_hospitals/SIBLEY MEMORIAL HOSPITAL/8.xlsx\n",
      "../DC_hospitals/SIBLEY MEMORIAL HOSPITAL/7.xls\n",
      "../DC_hospitals/SIBLEY MEMORIAL HOSPITAL/6.xls\n",
      "../DC_hospitals/SIBLEY MEMORIAL HOSPITAL/5.xls\n",
      "../DC_hospitals/MEDSTAR GEORGETOWN UNIVERSITY HOSPITAL/1.csv\n",
      "../DC_hospitals/MEDSTAR GEORGETOWN UNIVERSITY HOSPITAL/0.xlsx\n",
      "../DC_hospitals/MEDSTAR WASHINGTON HOSPITAL CENTER/0.xls\n",
      "../DC_hospitals/CHILDREN'S HOSPITAL NMC/0.csv\n",
      "../DC_hospitals/PROVIDENCE HOSPITAL WASHINGTON DC/0.csv\n",
      "../DC_hospitals/PROVIDENCE HOSPITAL WASHINGTON DC/2.xlsx\n",
      "../DC_hospitals/PROVIDENCE HOSPITAL WASHINGTON DC/1.xlsx\n",
      "../DC_hospitals/HOWARD UNIVERSITY HOSPITAL/1.csv\n",
      "../DC_hospitals/HOWARD UNIVERSITY HOSPITAL/0.xlsx\n",
      "../DC_hospitals/UNITED MEDICAL CENTER/StandardCharges12202018.xls\n",
      "../DC_hospitals/UNITED MEDICAL CENTER/DRGFile.xls\n",
      "../DC_hospitals/SIBLEY MEMORIAL HOSPITAL/4.xlsx\n",
      "../DC_hospitals/SIBLEY MEMORIAL HOSPITAL/8.xlsx\n",
      "../DC_hospitals/SIBLEY MEMORIAL HOSPITAL/7.xls\n",
      "../DC_hospitals/SIBLEY MEMORIAL HOSPITAL/6.xls\n",
      "../DC_hospitals/SIBLEY MEMORIAL HOSPITAL/5.xls\n",
      "../DC_hospitals/MEDSTAR GEORGETOWN UNIVERSITY HOSPITAL/1.csv\n",
      "../DC_hospitals/MEDSTAR GEORGETOWN UNIVERSITY HOSPITAL/0.xlsx\n",
      "../DC_hospitals/MEDSTAR WASHINGTON HOSPITAL CENTER/0.xls\n",
      "../DC_hospitals/CHILDREN'S HOSPITAL NMC/0.csv\n",
      "../DC_hospitals/PROVIDENCE HOSPITAL WASHINGTON DC/0.csv\n",
      "../DC_hospitals/PROVIDENCE HOSPITAL WASHINGTON DC/2.xlsx\n",
      "../DC_hospitals/PROVIDENCE HOSPITAL WASHINGTON DC/1.xlsx\n",
      "../DC_hospitals/HOWARD UNIVERSITY HOSPITAL/1.csv\n",
      "../DC_hospitals/HOWARD UNIVERSITY HOSPITAL/0.xlsx\n",
      "../DC_hospitals/UNITED MEDICAL CENTER/StandardCharges12202018.xls\n",
      "../DC_hospitals/UNITED MEDICAL CENTER/DRGFile.xls\n"
     ]
    }
   ],
   "source": [
    "# -------------------\n",
    "# Housekeeping\n",
    "# -------------------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import os\n",
    "import itertools as it\n",
    "\n",
    "# Set location of pricing files\n",
    "home_folder = \"../DC_hospitals/\"\n",
    "save_fname = \"DC_merge.csv\"\n",
    "\n",
    "# -------------------\n",
    "# Summarize\n",
    "# -------------------\n",
    "\n",
    "# Number of hospitals\n",
    "folders = os.listdir(home_folder)\n",
    "print(\"Number of Hospitals: \" + str(len(folders)))\n",
    "\n",
    "# Number of files\n",
    "FILES = []\n",
    "for folder in folders:\n",
    "    FILES += os.listdir(home_folder + folder)\n",
    "files = [x for x in FILES if x != \".DS_Store\"]\n",
    "print(\"Total Number of Files: \" + str(len(files)))\n",
    "\n",
    "# -------------------\n",
    "# Find unique files\n",
    "# -------------------\n",
    "\n",
    "unique_paths = get_unique_paths(home_folder)\n",
    "\n",
    "# -------------------\n",
    "# Inspect header labels & extract unique values\n",
    "# -------------------\n",
    "\n",
    "# Compile list of all the header labels\n",
    "labels = get_header_labels(unique_paths)\n",
    "print(labels)\n",
    "\n",
    "# Manually define keywords based on above results\n",
    "description_kws, code_kws, price_kws = ['description','name'],['code',\"drg\"],[\"chg\",\"price\",\"charge\"]\n",
    "\n",
    "# Get unique values for description/code columns\n",
    "desc_col, code_col = get_descriptive_labels(unique_paths,description_kws,code_kws)\n",
    "\n",
    "# -------------------\n",
    "# Merge Data\n",
    "# -------------------\n",
    "\n",
    "# Merge data based on description match\n",
    "d_desc = merge_data(unique_paths,price_kws,desc_col,description_kws)\n",
    "\n",
    "# Merge data based on code match\n",
    "d_code = merge_data(unique_paths,price_kws,code_col,code_kws)\n",
    "\n",
    "# Get mapping between codes and descriptions\n",
    "d_match = match_desc_code(unique_paths,desc_col,description_kws,code_kws)\n",
    "\n",
    "# -------------------\n",
    "# Merge Descriptions onto Code Data\n",
    "# -------------------\n",
    "\n",
    "# Get matching dataframe and remove duplicates from code column\n",
    "d1 = d_match.copy().drop_duplicates(subset =\"code\",keep=\"first\")\n",
    "d1.set_index('code',inplace=True)\n",
    "\n",
    "# Merge to dataframe\n",
    "d_codebased = d_code.copy().merge(d1,left_index=True, right_index=True,how='left')\n",
    "\n",
    "# -------------------\n",
    "# Merge Codes onto Descriptions Data\n",
    "# -------------------\n",
    "\n",
    "# Get matching dataframe and remove duplicates from description column\n",
    "d1 = d_match.copy().drop_duplicates(subset =\"desc\",keep=\"first\")\n",
    "d1.set_index('desc',inplace=True)\n",
    "\n",
    "# Merge to dataframe\n",
    "d_descbased = d_desc.copy().merge(d1,left_index=True, right_index=True,how='left')\n",
    "\n",
    "# -------------------\n",
    "# Merge into final dataset\n",
    "# -------------------\n",
    "\n",
    "d_final = d_descbased.groupby(by=d_descbased.columns, axis=1).mean().round(decimals=2)\n",
    "\n",
    "# Rearrange Columns\n",
    "d_final=d_final.reset_index()\n",
    "cols = d_final.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "d_final = d_final[cols]\n",
    "\n",
    "# Rename Columns\n",
    "d_final.rename(columns={'code':'Code','desc':'Description'},inplace=True)\n",
    "\n",
    "# Save\n",
    "d_final.to_csv(save_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Display Merged DataSet\n",
    "\n",
    "The first few rows of the resulting dataset are displayed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "      <th>CHILDREN'S HOSPITAL NMC</th>\n",
       "      <th>HOWARD UNIVERSITY HOSPITAL</th>\n",
       "      <th>MEDSTAR GEORGETOWN UNIVERSITY HOSPITAL</th>\n",
       "      <th>MEDSTAR WASHINGTON HOSPITAL CENTER</th>\n",
       "      <th>PROVIDENCE HOSPITAL WASHINGTON DC</th>\n",
       "      <th>SIBLEY MEMORIAL HOSPITAL</th>\n",
       "      <th>UNITED MEDICAL CENTER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GFT GELWEAVE THOR ARCH 12X10X8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6926.49</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CATH STEER 6F LG 8 ELECTRD LF</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>984.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SOLN DIANEAL 2500L-CAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CABLE HOMOG 1.6MM VIT 29.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1223.73</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BOLT LOCK 3.9MMX78MM BLUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>920.90</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>*TROPICAMIDE OPTH 1% SOL 2ML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SCR 5.5X45MM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3418.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PLATE DISTAL FIBULA 2.7MM 7H L</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4508.32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SCREW LOCKING T10 2.7*12MM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2366.89</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SET OATS RETROGRADE STER 8MM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2801.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>IMPLANT CONCORDE BULLET LOR 9*10*27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17665.18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SCR SYN O CANC 32T 6.5X120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>298.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>STETH ESO 9FR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SCR K2M S POLY DENALI 6.5X60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3808.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>TUBE VENT BUTTERFLY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BIT DRILL STRYKER J-LATCH 1.1*44.5*4MM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>710.74</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>HEPARIN (PORCINE) 1,000 UNIT/ML INJECTION SOLU...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.52</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>*PROPAFENONE 225MG TAB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>*FUROSEMIDE 20MG TAB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>STREPTOMYCIN 1G INJ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CATH FORTREX OTW .035 10X40X80</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>731.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SPECULUM VAG GRAVES MD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>hepatitis B immune globulin &gt; 1,560 unit/5 mL ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1447.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>COIL HS ADV 1.5MM 3CM SZ 10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4548.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>KIT AVAMAX STYLET STD 10X12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>383.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>T-1 BREATHING CIRCUIT 240CM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>464.16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>HC XRAY SPINE THORACIC 4+ VIEWS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>191.9</td>\n",
       "      <td>191.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>PLT TIB PROX LT 12H 4.5X226MM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5737.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GUIDEWIRE .014 CONFIANZA PRO 180CM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3781.57</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GUIDE WIRE 3.2MM*290MM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>380.77</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>SCR SYN O LOCK W/T4 ST 1.5X10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>551.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BRUSH CYTOLOGY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.42</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CATH GUIDE SHERPA NX 3DRC 7AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>123.82</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>NaN</td>\n",
       "      <td>*CEFIXIME 100MG/5ML LIQ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>401599212.0</td>\n",
       "      <td>COMPRESSION VEST FEMALE, 40</td>\n",
       "      <td>196.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>AV OPEN UPPERARM CEPHALIC VEIN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>BLADE HD ZIMMER 90 DEGREE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>439.56</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NaN</td>\n",
       "      <td>CATH BLN OTW STERLING 3.5X100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>713.35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>367819212.0</td>\n",
       "      <td>METHANOL (UMC)</td>\n",
       "      <td>197.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>197.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>NaN</td>\n",
       "      <td>GFT STENT ABD BIF 32X20X155MM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32017.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Code                                        Description  \\\n",
       "0           NaN                     GFT GELWEAVE THOR ARCH 12X10X8   \n",
       "1           NaN                      CATH STEER 6F LG 8 ELECTRD LF   \n",
       "2           NaN                     SOLN DIANEAL 2500L-CAL           \n",
       "3           NaN                         CABLE HOMOG 1.6MM VIT 29.5   \n",
       "4           NaN                          BOLT LOCK 3.9MMX78MM BLUE   \n",
       "5           NaN                     *TROPICAMIDE OPTH 1% SOL 2ML     \n",
       "6           NaN                     SCR 5.5X45MM                     \n",
       "7           NaN                     PLATE DISTAL FIBULA 2.7MM 7H L   \n",
       "8           NaN                         SCREW LOCKING T10 2.7*12MM   \n",
       "9           NaN                     SET OATS RETROGRADE STER 8MM     \n",
       "10          NaN                IMPLANT CONCORDE BULLET LOR 9*10*27   \n",
       "11          NaN                     SCR SYN O CANC 32T 6.5X120       \n",
       "12          NaN                     STETH ESO 9FR                    \n",
       "13          NaN                     SCR K2M S POLY DENALI 6.5X60     \n",
       "14          NaN                     TUBE VENT BUTTERFLY              \n",
       "15          NaN             BIT DRILL STRYKER J-LATCH 1.1*44.5*4MM   \n",
       "16          NaN  HEPARIN (PORCINE) 1,000 UNIT/ML INJECTION SOLU...   \n",
       "17          NaN                     *PROPAFENONE 225MG TAB           \n",
       "18          NaN                     *FUROSEMIDE 20MG TAB             \n",
       "19          NaN                     STREPTOMYCIN 1G INJ              \n",
       "20          NaN                     CATH FORTREX OTW .035 10X40X80   \n",
       "21          NaN                     SPECULUM VAG GRAVES MD           \n",
       "22          NaN  hepatitis B immune globulin > 1,560 unit/5 mL ...   \n",
       "23          NaN                     COIL HS ADV 1.5MM 3CM SZ 10      \n",
       "24          NaN                     KIT AVAMAX STYLET STD 10X12      \n",
       "25          NaN                        T-1 BREATHING CIRCUIT 240CM   \n",
       "26          NaN                    HC XRAY SPINE THORACIC 4+ VIEWS   \n",
       "27          NaN                     PLT TIB PROX LT 12H 4.5X226MM    \n",
       "28          NaN                 GUIDEWIRE .014 CONFIANZA PRO 180CM   \n",
       "29          NaN                             GUIDE WIRE 3.2MM*290MM   \n",
       "30          NaN                     SCR SYN O LOCK W/T4 ST 1.5X10    \n",
       "31          NaN                                     BRUSH CYTOLOGY   \n",
       "32          NaN                      CATH GUIDE SHERPA NX 3DRC 7AL   \n",
       "33          NaN                     *CEFIXIME 100MG/5ML LIQ          \n",
       "34  401599212.0                        COMPRESSION VEST FEMALE, 40   \n",
       "35          NaN                     AV OPEN UPPERARM CEPHALIC VEIN   \n",
       "36          NaN                          BLADE HD ZIMMER 90 DEGREE   \n",
       "37          NaN                      CATH BLN OTW STERLING 3.5X100   \n",
       "38  367819212.0                                     METHANOL (UMC)   \n",
       "39          NaN                     GFT STENT ABD BIF 32X20X155MM    \n",
       "\n",
       "    CHILDREN'S HOSPITAL NMC  HOWARD UNIVERSITY HOSPITAL  \\\n",
       "0                       NaN                         NaN   \n",
       "1                       NaN                         NaN   \n",
       "2                       NaN                         NaN   \n",
       "3                       NaN                         NaN   \n",
       "4                       NaN                         NaN   \n",
       "5                       NaN                         NaN   \n",
       "6                       NaN                         NaN   \n",
       "7                       NaN                         NaN   \n",
       "8                       NaN                         NaN   \n",
       "9                       NaN                         NaN   \n",
       "10                      NaN                         NaN   \n",
       "11                      NaN                         NaN   \n",
       "12                      NaN                         NaN   \n",
       "13                      NaN                         NaN   \n",
       "14                      NaN                         NaN   \n",
       "15                      NaN                         NaN   \n",
       "16                      NaN                         NaN   \n",
       "17                      NaN                         NaN   \n",
       "18                      NaN                         NaN   \n",
       "19                      NaN                         NaN   \n",
       "20                      NaN                         NaN   \n",
       "21                      NaN                         NaN   \n",
       "22                      NaN                         NaN   \n",
       "23                      NaN                         NaN   \n",
       "24                      NaN                         NaN   \n",
       "25                      NaN                         NaN   \n",
       "26                      NaN                       191.9   \n",
       "27                      NaN                         NaN   \n",
       "28                      NaN                         NaN   \n",
       "29                      NaN                         NaN   \n",
       "30                      NaN                         NaN   \n",
       "31                      NaN                         NaN   \n",
       "32                      NaN                         NaN   \n",
       "33                      NaN                         NaN   \n",
       "34                    196.0                       196.0   \n",
       "35                      NaN                         NaN   \n",
       "36                      NaN                         NaN   \n",
       "37                      NaN                         NaN   \n",
       "38                    197.0                       197.0   \n",
       "39                      NaN                         NaN   \n",
       "\n",
       "    MEDSTAR GEORGETOWN UNIVERSITY HOSPITAL  \\\n",
       "0                                      NaN   \n",
       "1                                      NaN   \n",
       "2                                      NaN   \n",
       "3                                      NaN   \n",
       "4                                      NaN   \n",
       "5                                      NaN   \n",
       "6                                      NaN   \n",
       "7                                      NaN   \n",
       "8                                      NaN   \n",
       "9                                      NaN   \n",
       "10                                     NaN   \n",
       "11                                     NaN   \n",
       "12                                     NaN   \n",
       "13                                     NaN   \n",
       "14                                     NaN   \n",
       "15                                     NaN   \n",
       "16                                     NaN   \n",
       "17                                     NaN   \n",
       "18                                     NaN   \n",
       "19                                     NaN   \n",
       "20                                     NaN   \n",
       "21                                     NaN   \n",
       "22                                     NaN   \n",
       "23                                     NaN   \n",
       "24                                     NaN   \n",
       "25                                     NaN   \n",
       "26                                   191.9   \n",
       "27                                     NaN   \n",
       "28                                     NaN   \n",
       "29                                     NaN   \n",
       "30                                     NaN   \n",
       "31                                     NaN   \n",
       "32                                     NaN   \n",
       "33                                     NaN   \n",
       "34                                   196.0   \n",
       "35                                     NaN   \n",
       "36                                     NaN   \n",
       "37                                     NaN   \n",
       "38                                   197.0   \n",
       "39                                     NaN   \n",
       "\n",
       "    MEDSTAR WASHINGTON HOSPITAL CENTER  PROVIDENCE HOSPITAL WASHINGTON DC  \\\n",
       "0                              6926.49                                NaN   \n",
       "1                                  NaN                                NaN   \n",
       "2                                47.75                                NaN   \n",
       "3                                  NaN                                NaN   \n",
       "4                                  NaN                                NaN   \n",
       "5                                 6.07                                NaN   \n",
       "6                              3418.37                                NaN   \n",
       "7                                  NaN                                NaN   \n",
       "8                                  NaN                                NaN   \n",
       "9                              2801.41                                NaN   \n",
       "10                                 NaN                                NaN   \n",
       "11                              298.86                                NaN   \n",
       "12                              117.56                                NaN   \n",
       "13                             3808.04                                NaN   \n",
       "14                              136.19                                NaN   \n",
       "15                                 NaN                                NaN   \n",
       "16                                 NaN                                NaN   \n",
       "17                               35.24                                NaN   \n",
       "18                                0.62                                NaN   \n",
       "19                               40.10                                NaN   \n",
       "20                              731.75                                NaN   \n",
       "21                              195.41                                NaN   \n",
       "22                                 NaN                            1447.99   \n",
       "23                             4548.63                                NaN   \n",
       "24                              383.75                                NaN   \n",
       "25                                 NaN                                NaN   \n",
       "26                                 NaN                                NaN   \n",
       "27                             5737.97                                NaN   \n",
       "28                                 NaN                                NaN   \n",
       "29                                 NaN                                NaN   \n",
       "30                              551.63                                NaN   \n",
       "31                                 NaN                                NaN   \n",
       "32                                 NaN                                NaN   \n",
       "33                               60.77                                NaN   \n",
       "34                                 NaN                             196.00   \n",
       "35                                 NaN                                NaN   \n",
       "36                                 NaN                                NaN   \n",
       "37                                 NaN                                NaN   \n",
       "38                                 NaN                             197.00   \n",
       "39                            32017.48                                NaN   \n",
       "\n",
       "    SIBLEY MEMORIAL HOSPITAL  UNITED MEDICAL CENTER  \n",
       "0                        NaN                    NaN  \n",
       "1                     984.75                    NaN  \n",
       "2                        NaN                    NaN  \n",
       "3                    1223.73                    NaN  \n",
       "4                     920.90                    NaN  \n",
       "5                        NaN                    NaN  \n",
       "6                        NaN                    NaN  \n",
       "7                    4508.32                    NaN  \n",
       "8                    2366.89                    NaN  \n",
       "9                        NaN                    NaN  \n",
       "10                  17665.18                    NaN  \n",
       "11                       NaN                    NaN  \n",
       "12                       NaN                    NaN  \n",
       "13                       NaN                    NaN  \n",
       "14                       NaN                    NaN  \n",
       "15                    710.74                    NaN  \n",
       "16                     19.52                    NaN  \n",
       "17                       NaN                    NaN  \n",
       "18                       NaN                    NaN  \n",
       "19                       NaN                    NaN  \n",
       "20                       NaN                    NaN  \n",
       "21                       NaN                    NaN  \n",
       "22                       NaN                    NaN  \n",
       "23                       NaN                    NaN  \n",
       "24                       NaN                    NaN  \n",
       "25                    464.16                    NaN  \n",
       "26                       NaN                    NaN  \n",
       "27                       NaN                    NaN  \n",
       "28                   3781.57                    NaN  \n",
       "29                    380.77                    NaN  \n",
       "30                       NaN                    NaN  \n",
       "31                     49.42                    NaN  \n",
       "32                    123.82                    NaN  \n",
       "33                       NaN                    NaN  \n",
       "34                       NaN                    NaN  \n",
       "35                       NaN                 2326.0  \n",
       "36                    439.56                    NaN  \n",
       "37                    713.35                    NaN  \n",
       "38                       NaN                    NaN  \n",
       "39                       NaN                    NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_final.head(n=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. To Do List\n",
    "\n",
    "1. **Fuzzy matching**. We have so far matched datasets based on exact matches of text descriptions or codes. But, as displayed above, this results in many blank cells. This is likely because hospitals define their services slightly differently. A fuzzy matching procedure would help to over come this. Take a look at [this blog post](https://medium.com/@categitau/fuzzy-string-matching-in-python-68f240d910fe) for ideas.\n",
    "2. **Use official codebooks for matching**. The mapping between text descriptions and codes has so far been done by exploiting pricing files that have both. We could instead use [official codebooks](https://www.findacode.com/drg/drg-diagnosis-related-group-codes.html) to perform this matching.\n",
    "3. **Identify unique files across all hospitals**. We have so far identified duplicates within a hospital's files by opening them and comparing the resulting dataframes. We need to do this across all hospitals, which will probably require a direct file comparison using techniques in [this post](https://stackoverflow.com/questions/748675/finding-duplicate-files-and-removing-them).\n",
    "4. **Ensure files are properly assigned**. For those that are duplicates, and for those hospitals with multiple price files, we need to determine whether they are correctly assigned to that hospital. For example, take a look at the [Sibley Hospital folder](https://www.dropbox.com/sh/e6au1phdxb6pdjn/AACw38q-M47wssX20I7y5NDra?dl=0), which contains multiple price files relating to other hospitals. A keyword search of hospital names would suffice in this case to distinguish the files."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
